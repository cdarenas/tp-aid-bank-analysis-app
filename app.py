#  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó      
# ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó      ‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó
# ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë         ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù
# ‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë         ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù 
# ‚ñà‚ñà‚ïë  ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù         ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë     
# ‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù          ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïù        
# Descripci√≥n: Script para AID - TP2.
# Este script realiza an√°lisis de datos avanzados con visualizaci√≥n y estad√≠sticas.
# Autor: Cristian D. Arenas
# Fecha: 07/11/2024


import streamlit as st

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats as stats

import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay

PAGE_CONFIG = {"page_title": "Fantasy Bank", "page_icon": ":bank:",
               "layout": "wide", "initial_sidebar_state": "collapsed"}

st.set_page_config(**PAGE_CONFIG)


def show_init_page():
    data_file = st.file_uploader("Subir CSV", type="csv")
    if data_file is not None:
        file_details = {"filename": data_file.name,
                        "filetype": data_file.type, "filesize": data_file.size}
        st.write(file_details)
        st.session_state.data_file = data_file
        df = pd.read_csv(data_file)

        st.subheader("Exploraci√≥n del dataset")
        #st.dataframe(df)
        st.write('Primeras 10 filas del DataFrame:')
        st.dataframe(df.head(10), use_container_width=True)

        # Creao un nuevo dataframe con nombres de columnas y tipos de datos
        df_info = pd.DataFrame({
            'Columnas': df.columns}).reset_index(drop=True)

        # Creo una nueva columna para una breve descripci√≥n de cada campo
        df_info['Description'] = ["ID del cliente", "Apellido", "Nivel Crediticio", "Pa√≠s", "Sexo", "Edad", "Antiguedad como cliente",
                                  "Saldo", "Cantidad de productos en uso", "Tiene tarjeta de cr√©dito", "Es miembro activo", "Salario estimado", "Abandon√≥"]
        df_info['Type'] = ["Discreta", "Cualitativa", "Cuantitativa Ordinal", "Categ√≥rica", "Categ√≥rica",
                           "Discreta", "Discreta", "Continua", "Discreta", "Binaria", "Binaria", "Continua", "Binaria"]

        st.subheader("Nombres de columnas, descripci√≥n y tipos de variables:")
        st.dataframe(df_info, use_container_width=True)

        # Calcular los datos faltantes por columna
        missing_data = df.isnull().sum()

        # Creao un DataFrame para visualizarlo mejor
        missing_data_df = pd.DataFrame(missing_data, columns=['Datos Faltantes'])
        # Filtro solo columnas con datos faltantes
        missing_data_df = missing_data_df[missing_data_df['Datos Faltantes'] > 0]

        # Mouestro el n√∫mero de datos faltantes por columna
        st.subheader("Cantidad de datos faltantes por columna: ")
        st.dataframe(missing_data_df)

        # Selecci√≥n de la estrategia de imputaci√≥n
        method = st.selectbox("Selecciona el m√©todo para manejar los datos faltantes:",
                          ("Eliminar filas", "Media", "Mediana", "Moda", "Valor fijo"))

        if method == "Eliminar filas":
            # Elimina filas con cualquier valor faltante
            df = df.dropna()
            st.write("Filas con valores faltantes eliminadas.")
        elif method == "Media":
            # Imputaci√≥n con la media
            # Solo columnas num√©ricas
            for col in df.select_dtypes(include='number').columns:
                mean_value = df[col].mean()
                df[col] = df[col].fillna(mean_value)
            st.write("Valores faltantes reemplazados por la media de cada columna num√©rica.")
        elif method == "Mediana":
            # Imputaci√≥n con la mediana
            # Solo columnas num√©ricas
            for col in df.select_dtypes(include='number').columns:
                median_value = df[col].median()
                df[col] = df[col].fillna(median_value)
            st.write("Valores faltantes reemplazados por la mediana de cada columna num√©rica.")
        elif method == "Moda":
            # Imputaci√≥n con la moda
            for col in df.columns:
                mode_value = df[col].mode()[0]  # Obtener la moda de cada columna
                df[col] = df[col].fillna(mode_value)
            st.write("Valores faltantes reemplazados por la moda de cada columna.")
        elif method == "Valor fijo":
            # Imputaci√≥n con un valor fijo, ingresado por el usuario
            fixed_value = st.text_input("Ingresa el valor fijo para reemplazar los valores faltantes:")
            if fixed_value:
                df = df.fillna(fixed_value)
                st.write(f"Valores faltantes reemplazados por el valor fijo: {fixed_value}")

        # Permito eliminar del dataframe los registros de pa√≠ses que no me interesen para el an√°lisis
        # Obtener un vector con los pa√≠ses sin repetir
        countries = df['Geography'].unique()
        countries_to_drop = st.multiselect("Selecciona los pa√≠ses que quieras excluir del DataFrame (M√°x 2):",
                                           countries,
                                           max_selections=2)
        # Mostrar los pa√≠ses seleccionados
        st.write('Pa√≠ses seleccionados:', countries_to_drop)

        # Excluir del dataframe las filas que tengan en la columna Geograf√≠a los pa√≠ses seleccionados
        df_filtered = df[~df['Geography'].isin(countries_to_drop)]

        st.session_state.dataframe = df_filtered
    else:
        st.write("Por favor, sube un archivo CSV para comenzar.")


def show_exploration_page():
    df = st.session_state.dataframe

    st.success("Descripci√≥n anal√≠tica del conjunto de datos:")

    # Descripci√≥n anal√≠tica del conjunto de datos
    df_describe = df.drop(columns=['CustomerId']).describe()
    st.dataframe(df_describe, use_container_width=True)

    st.markdown("<h2 style='font-size:16px;'>Distribuci√≥n de clientes seg√∫n su nivel crediticio</h2>", unsafe_allow_html=True)
    # Calcular los cuartiles del nivel crediticio
    st.write("La mayor√≠a de los clientes tienen un nivel crediticio entre 584 y 718, por lo tanto la distribuci√≥n de niveles crediticios est√° concentrada en este rango. Esto sugiere una cartera de clientes con un nivel de cr√©dito relativamente moderado. Un 25% se encuentra por debajo de ese rango, con un puntaje bajo y s√≥lo un 25% de los clientes posee un puntaje alto (718+).")

    # Histograma de la distribuci√≥n de edades
    fig = px.histogram(df, x='Age', nbins=10, title='Distribuci√≥n de las edades')
    fig.update_traces(marker=dict(line=dict(color='black', width=1)))
    st.plotly_chart(fig)

    st.write("Se puede apreciar que la distribuci√≥n de edades presenta una asimetr√≠a positiva (hacia la derecha), con una mayor concentraci√≥n de clientes adultos j√≥venes y una cola que se extiende hacia edades m√°s avanzadas.")
    st.write("La edad promedio de los clientes es de 39 a√±os y la mediana se ubica en 37 a√±os lo que nos indica que hay una distribuci√≥n relativamente asim√©trica, con un 50% de clientes por debajo de los 37 a√±os y un 50% por encima de los 37 a√±os.")

    # Gr√°fico de barras de la distribuci√≥n por pa√≠s
    fig = px.bar(df, x='Geography', title='Distribuci√≥n por pa√≠s')
    st.plotly_chart(fig)

    st.write("Se puede observar que Francia es el pa√≠s con mayor frecuencia de clientes del banco; aproximadamente el 50% de los clientes totales del banco pertenecen a este pa√≠s y la otra mitad est√° concentrada entre Espa√±a y Alemania.")

    cantidades = df['Gender'].value_counts()
    df_cantidades = cantidades.reset_index()
    df_cantidades.columns = ['Gender', 'Count']

    # Crear el gr√°fico de sectores (pie chart) con Plotly Express
    fig = px.pie(df_cantidades, 
             names='Gender',  # Columna para las categor√≠as
             values='Count',  # Columna con los valores
             color='Gender',  # Columna para asignar colores
             title="Distribuci√≥n de G√©nero de los Clientes",
             color_discrete_map={"Male": "royalblue", "Female": "lightpink"},  # Colores personalizados
             hole=0.3)

    # Mostrar el gr√°fico en Streamlit
    st.plotly_chart(fig)

    st.write("Respecto de la distribuci√≥n del g√©nero dentro del conjunto de clientes del banco, el 54.6% son hombres, podemos decir que no hay una diferencia significativa entre hombres y mujeres.")

    # Gr√°fico de cajas de Saldo por pa√≠s
    fig = px.box(df, x='Geography', y='Balance', title='Saldo en cuenta por pa√≠s')
    st.plotly_chart(fig)

    st.write("Respecto de la distribuci√≥n de saldo en cuenta por pa√≠s, podemos observar que para los casos de Espa√±a y Francia, la mediana es de aproximadamente 62.000 Euros y ambos pa√≠ses de acuerdo al Rango Intercuart√≠lico, tienen una variabilidad m√°s alta en los saldos que para el caso de Alemania. Para este √∫ltimo pa√≠s, la variabilidad es menor y la mayor concentraci√≥n se da en el rango de 103.000 y 137.000 Euros.")
    st.write("Estas diferencias de medias entre los pa√≠ses puede deberse a niveles de ingreso m√°s elevados en unos pa√≠ses que en otros.")
    st.write("Para entender si los salarios promedio de cada pa√≠s tienen impacto en los saldos, calculamos saldo y salario estimado promedio por pa√≠s y graficamos los resultados.")

    # Calcular saldo y salario promedio por pa√≠s
    saldo_pais = df.groupby("Geography")["Balance"].mean()
    salario_pais = df.groupby("Geography")["EstimatedSalary"].mean()

    comparacion_df = pd.DataFrame({
    "Saldo Promedio": saldo_pais,
    "Salario Promedio": salario_pais
    })

    # Crear gr√°fico de barras agrupadas
    fig = px.bar(comparacion_df.reset_index(), 
             x="Geography", 
             y=["Saldo Promedio", "Salario Promedio"],
             title="Comparaci√≥n de Saldo y Salario Promedio por Pa√≠s",
             barmode="group",
             labels={"value": "Monto", "variable": "M√©trica"},
             color_discrete_map={"Saldo Promedio": "#1f77b4", "Salario Promedio": "lightgreen"})

    st.plotly_chart(fig)

    st.write("Como podemos apreciar, los salarios promedios en los tres pa√≠ses son similares y s√≥lo el saldo en cuenta promedio en Alemania (120.000) difiere de los otros dos pa√≠ses, los cuales tienen promedios similares cercanos a los 60.000 Euros.")
    st.write("La distribuci√≥n de frecuencias podr√≠a sugerir que en Alemania los clientes podr√≠an inclinarse hacia la acumulaci√≥n de dinero en sus cuentas para ahorro u otros fines.")
    
    # An√°lisis gr√°fico de CreditScore seg√∫n Gender
    fig = px.box(df, x='Gender', y='CreditScore', title='Nivel crediticio por g√©nero')
    st.plotly_chart(fig)

    st.write("En relaci√≥n a la distribuci√≥n del puntaje de cr√©dito por g√©nero, el gr√°fico sugiere cierta simetr√≠a de los datos, medias similares para ambos grupos, con similar variabilidad de los datos. La mediana para el grupo femenino es de 652 y para el caso de los hombres es de 651.")

    # Crear una nueva columna en el DataFrame para agrupar la edad en intervalos de clase
    df['Age_Group'] = pd.cut(df['Age'], bins=[18, 30, 40, 50, 60, 70, 80], 
                         labels=["18-30", "31-40", "41-50", "51-60", "61-70", "71-80"])

    # Crear el box plot
    fig = px.box(df, 
             x="Age_Group", 
             y="Balance", 
             title="Distribuci√≥n de Saldo por Grupos de Edad",
             labels={"Age_Group": "Grupo de Edad", "Balance": "Saldo"},
             color="Age_Group",  # Asigna colores a cada grupo de edad para diferenciarlos
             points=False)  # Incluye todos los puntos de datos para ver posibles valores at√≠picos

    # Mostrar el gr√°fico en Streamlit
    st.plotly_chart(fig)

    st.write("En el boxplot podemos apreciar que todos los intervalos de clase o grupos de edades poseen una dispersi√≥n en sus saldos muy similar. La asimetr√≠a negativa de las cajas, nos da la idea de que la mayor√≠a de los clientes mantienen saldos por debajo de los 100.000 Euros y una peque√±a parte por encima de los 100.000 Euros. Para los casos de los grupos de 31-40 y de 51-60 a√±os, se aprecia una mayor dispersi√≥n de datos, con saldos acumulados m√°s extremos sugeridos por sus rangos de valores.")
    

def show_analysis_page():
    df = st.session_state.dataframe
    if st.session_state.data_file is not None:
        st.success("An√°lisis del conjunto de datos:")
        # Agrupar por G√©nero y Geograf√≠a y calcular la tasa de abandono
        tasa_abandono = df.groupby(['Gender', 'Geography'])['Exited'].mean() * 100
        # Convertir el resultado a un DataFrame
        tasa_abandono_df = tasa_abandono.reset_index()

        # Renombrar las columnas (cabeceras personalizadas)
        tasa_abandono_df.columns = ['G√©nero', 'Pa√≠s', 'Tasa de Abandono (%)']
        # Ordenar las filas por 'Tasa de Abandono (%)' de forma descendente
        tasa_abandono_df = tasa_abandono_df.sort_values(by='Tasa de Abandono (%)', ascending=False)
        st.dataframe(tasa_abandono_df)

        st.write("Como podemos apreciar en la tabla, Alemania tiene las tasas de abandono de clientes m√°s altas, en primer lugar las mujeres con un 37.55% y luego hombres con un 27.81%. Podemos concluir que el banco posee las tasas m√°s altas de abandono concentradas en el g√©nero femenino, por lo tanto se podr√≠a trabajar en estrategias orientadas a est√© grupo. Por otra parte tambi√©n orientar acciones en el mercado Alem√°n con el objetivo de reducir la tasa de abandono en general.")

        # 1. Distribuci√≥n de la Edad por Abandono (Histograma)
        st.subheader("Distribuci√≥n de Edad por Abandono")

        # Crear un histograma con Plotly Express
        fig_hist = px.histogram(df, x="Age", color="Exited", nbins=20,
                        labels={"Age": "Edad", "Exited": "Abandon√≥ (Exited)"})
        fig_hist.update_traces(marker=dict(line=dict(color='black', width=1)))
        st.plotly_chart(fig_hist)

        st.write("La mayor frecuencia de clientes que abandonan el banco se da en el rango de 39-50 a√±os. De todas formas, se puede apreciar que en los grupos de edades de clientes m√°s j√≥venes la proporci√≥n de clientes que abandonan la entidad es baja en comparaci√≥n con los grupos de edades m√°s avanzadas. Se puede interpretar que en clientes m√°s grandes, el nivel de deserci√≥n es m√°s alto.")

        st.subheader("Contrastes de Hip√≥tesis")
        st.write("Para corroborar la hip√≥tesis acerca de que los clientes del banco que abandonaron tienen un salario promedio significativamente m√°s bajo que los clientes que permanecen, se realiz√≥ una prueba t de Student para las medias de ambos grupos.")
        st.write("H‚ÇÄ: La media del salario de los clientes que abandonaron es igual a la media del salario de los clientes que no abandonaron.")
        st.write("H‚ÇÅ: La media del salario de los clientes que abandonaron es menor que la media del salario de los clientes que no abandonaron.")
        # Filtrar los salarios de los clientes que abandonaron (Exited = 1) y los que no (Exited = 0)
        salarios_abandonaron = df[df['Exited'] == 1]['EstimatedSalary']
        salarios_no_abandonaron = df[df['Exited'] == 0]['EstimatedSalary']

        # Realizar la prueba t de Student para muestras independientes
        t_stat, p_value = stats.ttest_ind(salarios_abandonaron, salarios_no_abandonaron, alternative='less')

        # Mostrar los resultados de la prueba
        st.write("Estad√≠stico t:", t_stat)
        st.write("Valor p:", p_value)

        # Conclusi√≥n
        alpha = 0.05  # Nivel de significancia
        if p_value < alpha:
            st.write("Rechazamos la hip√≥tesis nula. Existe evidencia suficiente para afirmar que los clientes que abandonaron tienen un salario medio m√°s bajo.")
        else:
            st.write("No rechazamos la hip√≥tesis nula. No hay evidencia suficiente para afirmar que los clientes que abandonaron la entidad tienen un salario medio m√°s bajo.")

        st.success("Conclusiones finales:")
        st.write("Podemos concluir que podr√≠an existir cuestiones demogr√°ficas, culturales, de g√©nero y relacionadas con la edad que pueden incidir en los clientes que deciden abandonar el banco. No se encontraron relaciones entre Abandono y variables como Credit Score, Salario Estimado o Saldo acumulado; es decir, no necesariamente los clientes que abandonan a la entidad suelen tener un nivel crediticio bajo, sueldos bajos o saldos acumulados bajos. Ambos grupos (Exited=0 y Exited=1) en la distribuci√≥n de datos de las variables mencionadas anteriormente, poseen una similitud en cuanto a la concentraci√≥n de los datos centrales y la variabilidad de los mismos, lo que nos sugiere que probalemente existen otros factores que pueden impactar en la decisi√≥n de abandonar el banco.")


def show_logistic_regression():
    df = st.session_state.dataframe
    if st.session_state.data_file is not None:
        # Crear una columna con el √≠ndice original
        df['OriginalIndex'] = df.index
        st.subheader("Vista previa del dataset")
        st.write(df.head())
        # Seleccionar caracter√≠sticas y objetivo
        st.sidebar.subheader("Seleccionar columnas")
        features = st.sidebar.multiselect("Selecciona las columnas de caracter√≠sticas (X)", df.columns)
        st.success("Para la variable independiente (y) el modelo trabajar√° con 'Exited' (Abandono)")
        if features:
            X = df[features].values
            y = df.iloc[:, 12].values
            original_indices = df['OriginalIndex'].values  # √çndices originales
            # Divisi√≥n en conjunto de entrenamiento y prueba
            test_size = st.radio("Selecciona el porcentaje para Test", [0.1, 0.2, 0.3])
            X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(X, y, original_indices, test_size = test_size, random_state = 0)
            # Escalado de variables
            sc_X = StandardScaler()
            X_train = sc_X.fit_transform(X_train)
            X_test = sc_X.transform(X_test)
            # Entrenar modelo de regresi√≥n log√≠stica
            st.sidebar.subheader("Entrenar modelo")
            if st.sidebar.button("Entrenar"):
                classifier = LogisticRegression(random_state = 0)
                classifier.fit(X_train, y_train)
                # Predicci√≥n de los resultados con el Conjunto de Testing
                y_pred  = classifier.predict(X_test)
                # Mostramos resultados del modelo
                st.subheader("Resultados del modelo")
                # Matriz de confusi√≥n
                cm = confusion_matrix(y_test, y_pred)
                st.text("Matriz de Confusi√≥n:")
                st.write(cm)
                st.text("M√©tricas de clasificaci√≥n:")
                st.text(classification_report(y_test, y_pred))
                # Visualizar la matriz de confusi√≥n
                st.subheader("Gr√°fico de la matriz de confusi√≥n:")
                cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classifier.classes_)
                fig, ax = plt.subplots(figsize=(5, 5))
                cm_display.plot(cmap="Blues", ax=ax)
                fig.patch.set_alpha(0.0)
                ax.set_facecolor('none')
                 # Cambiar color de las etiquetas a blanco o amarillo
                ax.xaxis.label.set_color('white')
                ax.yaxis.label.set_color('white')
                ax.tick_params(axis='both', colors='white')  # Color de las etiquetas de los ejes
                for label in ax.get_xticklabels() + ax.get_yticklabels():
                    label.set_color('yellow') 
                st.pyplot(fig)
                # Mostrar predicciones con √≠ndices originales
                st.subheader("Predicciones")
                # Asociar las predicciones con los √≠ndices originales
                results = pd.DataFrame({
                    'OriginalIndex': indices_test,
                    'Predicted': y_pred,
                    'Actual': y_test
                }).sort_values(by='OriginalIndex')
                st.dataframe(results, use_container_width=True)


def main():
    # Inicializo variables globales en la session
    if 'data_file' not in st.session_state:
        st.session_state.data_file = None
    if 'dataframe' not in st.session_state:
        st.session_state.dataframe = None

    st.sidebar.success("Menu")
    menu = ["üè† Inicio", "üìù Descipci√≥n de datos", "üìä An√°lisis", "üß† Regresi√≥n Log√≠stica", "Acerca de..."]
    selected_option = st.sidebar.selectbox("Opciones", menu)

    if selected_option == "üè† Inicio":
        st.header("An√°lisis Inteligente de Datos")
        st.subheader("MCD - Universidad Austral")
        st.subheader("TP 2 - Clientes del Banco X")
        st.write("Autor: Cristian D. Arenas")
        st.warning("Introducci√≥n")
        st.write("El Banco X con sucursales en tres pa√≠ses de Europa y casa central en Alemania, viene experimentando desde hace tres a√±os un incremento en la tasa anual de abandono. Esta tasa se ha ido incrementando en los √∫ltimos a√±os y se desea conocer el perfil de los clientes, con el fin de poder dise√±ar un plan para retenerlos como usuarios de sus productos y servicios.")
        st.write("Alcance del estudio: muestra y objetivos")
        st.write("El estudio tiene como objetivo analizar las caracter√≠sticas de los clientes del banco para entender el perfil de los mismos.")
        st.write("Para la realizaci√≥n del estudio y an√°lisis se utiliz√≥ un dataset que almacena 10.000 filas que contienen datos de clientes de distintas sucursales del banco.")
        st.write("El dataset llamado 'Bank Customer Churn' puede descargarse desde la siguiente URL: https://mavenanalytics.io/data-playground?dataStructure=Single%20table&order=date_added%2Cdesc")
        st.write("Para la presentaci√≥n del an√°lisis y conclusiones, se decidi√≥ desarrollar una web app con Python, utilizando el framework Streamlit")
        st.write("P√°gina web oficial de Streamlit: https://streamlit.io/")

        st.success("Selecci√≥n y limpieza de los datos")
        show_init_page()
    elif selected_option == "üìù Descipci√≥n de datos":
        st.subheader("Descripci√≥n anal√≠tica y gr√°fica de los datos")
        show_exploration_page()
    elif selected_option == "üìä An√°lisis":
        st.subheader("An√°lisis de Datos - Abandono de Clientes")
        show_analysis_page()
    elif selected_option == "üß† Regresi√≥n Log√≠stica":
        st.subheader("Regresi√≥n Log√≠stica - Entrenamiento para predicci√≥n de abandono")
        show_logistic_regression()
    else:
        st.subheader("Acerca de...")
        st.write("Esta aplicaci√≥n fue creada para presentar como trabajo pr√°ctico de la materia An√°lisis Inteligentes de Datos. Los datos utilizados son ficticios y el dataset fue descargado del sitio https://mavenanalytics.io")
        st.write("Las consignas utilizadas en el trabajo pr√°ctico y relacionadas con el caso ficticio del Banco X, no tienen relaci√≥n con un caso real.")


if __name__ == '__main__':
    main()
